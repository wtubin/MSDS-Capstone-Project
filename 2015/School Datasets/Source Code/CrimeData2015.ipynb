{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NCSBI 2014-2015 Raw Datasets by County\n",
    "* This program downloads all original datasets from http://crimereporting.ncsbi.gov/Reports.aspx and saves them as .csv files. These data files are used to create all the flattened and machine learning datasets\n",
    "    1. This program will dowload specific year data from each web page\n",
    "    2. It will loop the though 100 counties to get related year data\n",
    "    3. Get the school list from profile file, then left join with the crime rate got from step 2.\n",
    "    4. We generate a new csv file and save specific year data for all of the North Carolina counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaraies\n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015\n",
    "\n",
    "# root URL for the crime rate in 2017 including 10 years dataset for each county, but we only want to e\n",
    "rootPath = 'http://crimereporting.ncsbi.gov/public/2017/CrimeTrds/IndexRateCoTrd/report1/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the header\n",
    "\n",
    "url = 'http://crimereporting.ncsbi.gov/public/2017/CrimeTrds/IndexRateCoTrd/report1/1.htm'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "# fourth table has the header\n",
    "table = soup.findAll('table')[4]\n",
    "headers = []\n",
    "header = []\n",
    "header.append('County')\n",
    "\n",
    "# header is in the first row\n",
    "for val in table.find_all('tr')[0].find_all('td'):\n",
    "    #print(val.text)\n",
    "    header.append(val.text)\n",
    "headers.append(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCrimeDataByYear(url,yearToExtract):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    title = soup.findAll('table')[3]\n",
    "    county = title.findAll('td')[0].text + ' County'\n",
    "    \n",
    "    table = soup.findAll('table')[4]\n",
    "   \n",
    "    for row in table.find_all('tr')[1:]:\n",
    "\n",
    "        data =[]\n",
    "        data.append(county)\n",
    "        firstCol = True\n",
    "        for val in row.find_all('td'):\n",
    "            if(firstCol==True):\n",
    "                yearVal = int(val.text)\n",
    "            fieldVal = val.text\n",
    "            if(fieldVal == '\\xa0'):\n",
    "                fieldVal = ''\n",
    "            data.append(fieldVal)\n",
    "            firstCol=False\n",
    "        #print(yearVal,year)\n",
    "\n",
    "        if(yearVal==yearToExtract):\n",
    "            #print('true')\n",
    "            crime.loc[len(crime)] = data\n",
    "    \n",
    "    #print(headers)\n",
    "    #print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for all of the counties to get the data for specific year\n",
    "crime =pd.DataFrame(columns = list(headers)[0])\n",
    "for i in range(1,101):\n",
    "    url = rootPath+str(i)+'.htm'\n",
    "    getCrimeDataByYear(url,year)\n",
    "\n",
    "crime.columns = ['County','Year','Crime_Rate_Index_Rate'\n",
    "                ,'Crime_Rate_Violent_Rate','Crime_Rate_Property_Rate','Crime_Rate_Murder_Rate'\n",
    "                ,'Crime_Rate_Rape_Rate','Crime_Rate_Robbery_Rate'\n",
    "                ,'Crime_Rate_Assault_Rate','Crime_Rate_Burglary_Rate'\n",
    "                ,'Crime_Rate_Larceny_Rate','Crime_Rate_MVT_Rate','Crime_Rate_Arson_Rate']\n",
    "    \n",
    "# Import the profile \n",
    "inputFile = '../../Raw Datasets/profile.csv'\n",
    "profile = pd.read_csv(inputFile, low_memory=False, dtype={'unit_code': object})\n",
    "# get the lea \n",
    "lea = profile[['unit_code','School_Name','Lea_Name']].drop_duplicates()\n",
    "lea['County'] = lea['Lea_Name'].str.replace(r' Schools', '')\n",
    "lea = lea.sort_values(by=['County'])\n",
    "\n",
    "# join the profile with crime dataset\n",
    "crime_combined = pd.merge(lea , crime, on = 'County', how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the crime data frome to csv file\n",
    "crime_combined.to_csv(r'../CrimeData2015.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
